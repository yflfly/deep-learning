下面内容来源：
https://www.zhihu.com/question/59201590/answer/167392763

深度度学习中防止过拟合的方法
1）什么是过拟合
过拟合是指在模型参数拟合过程中的问题，由于训练数据包含抽样误差，训练时，复杂的模型将抽样误差也考虑在内，将抽样误差也进行了很好的拟合
具体表现就是最终模型在训练集上效果好；在测试集上效果差。模型泛化能力弱。
2）为什么会出现过拟合的现象
这是因为我们拟合的模型一般是用来预测未知的结果（不在训练集内），过拟合虽然在训练集上效果好，但是在实际使用时（测试集）效果差。同时，在很多问题上，我们无法穷尽所有状态，不可能将所有情况都包含在训练集上。所以，必须要解决过拟合问题。
3）解决办法
（1）获取更多的数据
这是解决过拟合最有效的方法，只要给足够多的数据，让模型 看见 尽可能多的 例外情况，它就会不断修正自己，从而得到更好的结果
（2）使用合适的模型
过拟合主要是有两个原因造成的：数据太少+模型太复杂。所以，我们可以通过使用合适复杂度的模型来防止过拟合问题，让其足够拟合真正的规则，同时又不至于拟合太多抽样误差。


对于神经网络而言，我们可以从以下四个方面来限制网络能力：
1、网络结构 Architecture
这个很好理解，减少网络的层数、神经元个数等均可以限制网络的拟合能力；

2、训练时间 Early stopping对于每个神经元而言，其激活函数在不同区间的性能是不同的
因为我们在初始化网络的时候一般都是初始为较小的权值。训练时间越长，部分网络权值可能越大。如果我们在合适时间停止训练，就可以将网络的能力限制在一定范围内。

3、限制权值 Weight-decay，也叫正则化（regularization）
这类方法直接将权值的大小加入到 Cost 里，在训练的时候限制权值变大
训练过程需要降低整体的 Cost，这时候，一方面能降低实际输出与样本之间的误差 [公式] ，也能降低权值大小。

4、增加噪声 Noise
